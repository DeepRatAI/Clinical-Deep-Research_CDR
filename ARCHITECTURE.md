# CDR Architecture

> Pipeline design, data flow, and stage contracts for Clinical Deep Research v0.1

## Overview

CDR is a **13-node LangGraph StateGraph** pipeline that automates clinical evidence retrieval, screening, extraction, bias assessment, synthesis, and verification.

<div align="center">
<img src="docs/assets/architecture.svg" alt="CDR Pipeline Architecture" width="800" />
</div>

The pipeline is organized into four color-coded phases:

| Phase | Color | Nodes |
|-------|-------|-------|
| **Retrieval** | ğŸ”µ Blue | parse_question, plan_search, retrieve, deduplicate |
| **Screening** | ğŸŸ¡ Amber | screen, parse_docs, extract_data |
| **Analysis** | ğŸŸ£ Purple / ğŸ”´ Red | assess_rob2, synthesize, critique |
| **Output** | ğŸŸ¢ Green | verify, compose, publish |

## Data Model

All data flows through **`CDRState`** â€” a Pydantic model that holds every artifact produced by the pipeline. Each node reads from and writes to specific fields on this state.

```
CDRState
â”œâ”€â”€ question: str                           # Original clinical question
â”œâ”€â”€ pico: PICO                              # Structured P-I-C-O
â”œâ”€â”€ search_plan: SearchPlan                 # Planned queries
â”œâ”€â”€ executed_searches: list[ExecutedSearch]  # PRISMA-S audit trail
â”œâ”€â”€ records: list[Record]                   # Retrieved evidence
â”œâ”€â”€ screening_decisions: list[ScreeningDecision]
â”œâ”€â”€ snippets: list[Snippet]                 # Citable passages
â”œâ”€â”€ study_cards: list[StudyCard]            # Structured extractions
â”œâ”€â”€ rob2_results: list[RoB2Result]          # Bias assessment (RCTs)
â”œâ”€â”€ robins_i_results: list[ROBINSIResult]   # Bias assessment (observational)
â”œâ”€â”€ claims: list[EvidenceClaim]             # Evidence claims
â”œâ”€â”€ synthesis: SynthesisResult              # Synthesis metadata
â”œâ”€â”€ critiques: list[Critique]               # Adversarial findings
â”œâ”€â”€ verification: list[VerificationResult]  # Per-claim checks
â”œâ”€â”€ composed_hypotheses: list[dict]         # A+Bâ‡’C inferences
â”œâ”€â”€ prisma_counts: PRISMACounts             # PRISMA flow data
â”œâ”€â”€ report: dict                            # Final JSON output
â”œâ”€â”€ status: RunStatus                       # Pipeline status
â””â”€â”€ errors: list[str]                       # Runtime errors
```

## Stage Contracts

Each node has typed inputs and outputs. **If a contract is violated, the pipeline fails loudly.**

### 1. parse_question

| | Type | Description |
|---|---|---|
| **In** | `str` (question) | Natural-language clinical question |
| **Out** | `PICO` | population, intervention, comparator, outcome, study_types |

**Invariants**: population, intervention, outcome â‰¥3 chars; comparator_source is set.

### 2. plan_search

| | Type | Description |
|---|---|---|
| **In** | `PICO` | Structured question |
| **Out** | `SearchPlan` | PubMed query (MeSH + Boolean), CT.gov query (â‰¤500 chars) |

### 3. retrieve

| | Type | Description |
|---|---|---|
| **In** | `SearchPlan` | Planned queries |
| **Out** | `list[Record]` + `list[ExecutedSearch]` | Retrieved records + PRISMA-S audit |

**Sources**: PubMed E-utilities, ClinicalTrials.gov v2 API.

### 4. deduplicate

| | Type | Description |
|---|---|---|
| **In** | `list[Record]` | All retrieved records |
| **Out** | `list[Record]` | Deduplicated (PMID + title similarity â‰¥0.85) |

**Invariant**: `len(output) + duplicates_removed == len(input)`.

### 5. screen

| | Type | Description |
|---|---|---|
| **In** | `list[Record]` + `PICO` | Records + criteria |
| **Out** | `list[ScreeningDecision]` | Per-record include/exclude with reason code |

**Invariant**: Every record gets exactly one decision. Every exclusion has a `reason`.

### 6. parse_docs

| | Type | Description |
|---|---|---|
| **In** | `list[Record]` (included) | Records passing screening |
| **Out** | `list[Snippet]` | Text passages with section + source_ref |

**Source**: PMC Open Access (JATS XML). Abstracts used as fallback.

### 7. extract_data

| | Type | Description |
|---|---|---|
| **In** | `list[Snippet]` + `list[Record]` | Evidence text |
| **Out** | `list[StudyCard]` | Structured study summaries (type, sample size, outcomes) |

### 8. assess_rob2

| | Type | Description |
|---|---|---|
| **In** | `list[StudyCard]` + `list[Snippet]` | Study data |
| **Out** | `list[RoB2Result]` + `list[ROBINSIResult]` | Bias assessment |

**Invariant**: RoB2 = exactly 5 domains; ROBINS-I = exactly 7 domains.

### 9. synthesize

| | Type | Description |
|---|---|---|
| **In** | `list[StudyCard]` + `list[Snippet]` + `list[RoB2Result]` | All evidence |
| **Out** | `list[EvidenceClaim]` + `SynthesisResult` | Claims with traceability |

**Invariant**: Every claim has `supporting_snippet_ids` (â‰¥1). Claim text 20â€“1000 chars.

### 10. critique

| | Type | Description |
|---|---|---|
| **In** | `list[EvidenceClaim]` + `list[Snippet]` | Claims + evidence |
| **Out** | `list[Critique]` | Adversarial findings with dimension + severity |

### 11. verify

| | Type | Description |
|---|---|---|
| **In** | `list[EvidenceClaim]` + `list[Snippet]` | Claims + evidence |
| **Out** | `dict[str, VerificationResult]` | Per-claim: verified/partial/contradicted/unverifiable |

**Quality gates**: citation_coverage â‰¥90%, snippet_coverage = 100%.

### 12. compose

| | Type | Description |
|---|---|---|
| **In** | `list[EvidenceClaim]` (verified) | Verified claims |
| **Out** | `list[ComposedHypothesis]` | A+Bâ‡’C inferences with confidence + reasoning trace |

### 13. publish

| | Type | Description |
|---|---|---|
| **In** | `CDRState` (complete) | All pipeline artifacts |
| **Out** | Report JSON + `RunStatus` | Validated output conforming to `schemas/report.schema.json` |

**Invariant**: Clinical disclaimer always present. `unpublishable` if quality gates fail.

## External Dependencies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                CDR Pipeline                  â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ LLM      â”‚  â”‚ Retrieval  â”‚  â”‚ Storage â”‚ â”‚
â”‚  â”‚ Providers â”‚  â”‚ APIs       â”‚  â”‚         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚              â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ Gemini  â”‚   â”‚ PubMed    â”‚  â”‚ SQLite  â”‚
   â”‚ OpenAI  â”‚   â”‚ E-utils   â”‚  â”‚ (local) â”‚
   â”‚ Anthropicâ”‚   â”‚           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚ HF      â”‚   â”‚ CT.gov    â”‚
   â”‚ Groq    â”‚   â”‚ v2 API    â”‚
   â”‚ Cerebrasâ”‚   â”‚           â”‚
   â”‚ OpenRtr â”‚   â”‚ PMC OA    â”‚
   â”‚ Cloudflrâ”‚   â”‚ JATS XML  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Design Decisions

| Decision | Rationale | Reference |
|----------|-----------|-----------|
| LangGraph StateGraph (not agents) | Predictable execution, typed state, testable nodes | [CASE_STUDY.md](CASE_STUDY.md#1-langgraph-over-bare-agents) |
| 20 Pydantic models with strict validation | Contract enforcement at every boundary | [CASE_STUDY.md](CASE_STUDY.md#2-pydantic-contracts-over-free-form-dicts) |
| Verification before publish | Safety: unsupported claims never published | [CASE_STUDY.md](CASE_STUDY.md#3-verification-before-publish-not-optional) |
| Multi-provider LLM, no fine-tuning | Reproducibility across providers | [CASE_STUDY.md](CASE_STUDY.md#4-multi-provider-llm-with-no-fine-tuning) |
| PMC OA fulltext only | Legal, free, structured (JATS) | [CASE_STUDY.md](CASE_STUDY.md#5-fulltext-via-pmc-open-access-only) |
| SQLite persistence | Zero-config, sufficient for v0.1 | [CASE_STUDY.md](CASE_STUDY.md#6-sqlite-for-persistence-not-postgres) |
| Immutable records (Pydantic frozen) | PRISMA count correctness | [INCIDENTS.md](INCIDENTS.md#inc-003-prisma-count-arithmetic-failures) |

## File Organization

```
src/cdr/
â”œâ”€â”€ api/                    # FastAPI routes (18 endpoints)
â”œâ”€â”€ composition/            # A+Bâ‡’C hypothesis generation
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ schemas.py          # 20 Pydantic models (CDRState, PICO, etc.)
â”‚   â””â”€â”€ enums.py            # All enum types
â”œâ”€â”€ evaluation/             # Golden set, metrics, semantic harness
â”œâ”€â”€ extraction/             # Study card extraction (DSPy-based)
â”œâ”€â”€ llm/                    # Multi-provider LLM abstraction
â”‚   â”œâ”€â”€ factory.py          # Provider factory
â”‚   â””â”€â”€ providers/          # 8 provider implementations
â”œâ”€â”€ observability/          # Tracing + metrics (OpenTelemetry-compatible)
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ graph.py            # LangGraph graph builder + runner (~500 lines)
â”‚   â””â”€â”€ nodes/              # 7 node modules (split from monolith)
â”œâ”€â”€ publisher/              # Markdown, JSON, HTML report generation
â”œâ”€â”€ retrieval/              # PubMed, CT.gov, PMC clients
â”œâ”€â”€ screening/              # PICO-based inclusion/exclusion
â”œâ”€â”€ storage/                # SQLite RunStore with checkpoints
â””â”€â”€ verification/           # Citation coverage + entailment checks
```

## Further Reading

- [Pipeline contracts (detailed)](docs/contracts/pipeline_contracts.md) â€” Full I/O specification per stage
- [Report JSON Schema](schemas/report.schema.json) â€” Machine-readable output contract
- [CASE_STUDY.md](CASE_STUDY.md) â€” Design decisions and tradeoffs
- [EVAL.md](EVAL.md) â€” Evaluation methodology
