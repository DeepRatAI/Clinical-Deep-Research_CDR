"""
CDR Publisher Layer

Report generation in multiple formats (Markdown, JSON, HTML).
"""

from __future__ import annotations

import json
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING

from cdr.core.enums import GRADECertainty, Section, VerificationStatus
from cdr.core.schemas import (
    CDRState,
    EvidenceClaim,
    ExecutedSearch,
    PRISMACounts,
    RoB2Result,
    StudyCard,
    VerificationResult,
)
from cdr.observability.tracer import tracer

if TYPE_CHECKING:
    from cdr.synthesis.synthesizer import SynthesisResult
    from cdr.skeptic.skeptic_agent import CritiqueResult


# =============================================================================
# REPORT TEMPLATES
# =============================================================================

MARKDOWN_TEMPLATE = """# {title}

**Generated**: {timestamp}
**Run ID**: {run_id}

---

## Executive Summary

{executive_summary}

---

## Research Question

{research_question}

### PICO Framework

- **Population**: {pico_population}
- **Intervention**: {pico_intervention}
- **Comparator**: {pico_comparator}
- **Outcome**: {pico_outcome}

---

## Methods

### Search Strategy

{search_strategy}

### Study Selection (PRISMA)

{prisma_flowchart}

**Summary**:
- Studies identified: {identified}
- After deduplication: {deduplicated}
- Screened: {screened}
- Full-text assessed: {assessed}
- Included in synthesis: {included}

### Risk of Bias Assessment

{rob2_summary}

---

## Results

### Included Studies

{study_summaries}

### Evidence Synthesis

{synthesis_narrative}

### GRADE Summary of Findings

{grade_table}

---

## Discussion

### Key Findings

{key_findings}

### Limitations

{limitations}

### Implications

{implications}

---

## Verification Status

{verification_summary}

---

## References

{references}

---

## Appendices

### A. Complete Study Characteristics

{appendix_studies}

### B. Risk of Bias Details

{appendix_rob2}

### C. Data Extraction Forms

{appendix_data}

---

*This report was generated by Clinical Deep Research (CDR).*
*\u26a0\ufe0f NOT MEDICAL ADVICE. This report is machine-generated and should not be used for clinical decision-making. All findings require independent verification by qualified professionals.*
*All claims are evidence-backed and verifiable.*
"""


HTML_TEMPLATE = """<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }}
        h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}
        h2 {{ color: #34495e; margin-top: 30px; }}
        h3 {{ color: #7f8c8d; }}
        .meta {{ color: #95a5a6; font-size: 0.9em; }}
        .claim {{
            background: #ecf0f1;
            padding: 15px;
            margin: 15px 0;
            border-left: 4px solid #3498db;
            border-radius: 4px;
        }}
        .claim-high {{ border-left-color: #27ae60; }}
        .claim-moderate {{ border-left-color: #f39c12; }}
        .claim-low {{ border-left-color: #e74c3c; }}
        .certainty {{
            display: inline-block;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 0.8em;
            font-weight: bold;
        }}
        .certainty-high {{ background: #27ae60; color: white; }}
        .certainty-moderate {{ background: #f39c12; color: white; }}
        .certainty-low {{ background: #e74c3c; color: white; }}
        .prisma {{
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 10px;
            margin: 20px 0;
        }}
        .prisma-box {{
            background: #3498db;
            color: white;
            padding: 10px;
            text-align: center;
            border-radius: 4px;
        }}
        .verification {{
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
        }}
        .verified {{ background: #d4edda; border: 1px solid #c3e6cb; }}
        .partial {{ background: #fff3cd; border: 1px solid #ffeeba; }}
        .contradicted {{ background: #f8d7da; border: 1px solid #f5c6cb; }}
        .unverifiable {{ background: #e2e3e5; border: 1px solid #d6d8db; }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }}
        th {{ background: #3498db; color: white; }}
        tr:nth-child(even) {{ background: #f2f2f2; }}
        .snippet {{
            font-style: italic;
            color: #7f8c8d;
            border-left: 2px solid #bdc3c7;
            padding-left: 10px;
            margin: 10px 0;
        }}
        .footer {{
            margin-top: 50px;
            padding-top: 20px;
            border-top: 1px solid #eee;
            color: #95a5a6;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    {content}
    <div class="footer">
        <p>Generated by Clinical Deep Research (CDR) | {timestamp}</p>
        <p><strong>\u26a0\ufe0f NOT MEDICAL ADVICE.</strong> This report is machine-generated and should not be used for clinical decision-making. All findings require independent verification by qualified professionals.</p>
    </div>
</body>
</html>"""


# =============================================================================
# PUBLISHER CLASS
# =============================================================================


class Publisher:
    """Generate reports from CDR results."""

    def __init__(
        self,
        output_dir: Path | str = "reports",
        include_appendices: bool = True,
        include_verification: bool = True,
    ) -> None:
        """Initialize publisher.

        Args:
            output_dir: Directory for output files
            include_appendices: Include detailed appendices
            include_verification: Include verification details
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.include_appendices = include_appendices
        self.include_verification = include_verification

    def publish(
        self,
        state: CDRState,
        synthesis_result: "SynthesisResult",
        critique_result: "CritiqueResult | None" = None,
        verification_results: dict[str, VerificationResult] | None = None,
        formats: list[str] | None = None,
    ) -> PublishResult:
        """Publish CDR results to files.

        Args:
            state: Current CDR workflow state
            synthesis_result: Evidence synthesis results
            critique_result: Optional skeptic critique results
            verification_results: Optional verification results
            formats: Output formats (default: ["markdown", "json"])

        Returns:
            PublishResult with paths to generated files
        """
        with tracer.start_span("publisher.publish") as span:
            formats = formats or ["markdown", "json"]
            span.set_attribute("formats", ",".join(formats))

            outputs = {}
            timestamp = datetime.now().isoformat()
            base_name = f"cdr_report_{state.run_id}"

            if "markdown" in formats:
                md_content = self._generate_markdown(
                    state, synthesis_result, critique_result, verification_results
                )
                md_path = self.output_dir / f"{base_name}.md"
                md_path.write_text(md_content, encoding="utf-8")
                outputs["markdown"] = md_path

            if "json" in formats:
                json_content = self._generate_json(
                    state, synthesis_result, critique_result, verification_results
                )
                json_path = self.output_dir / f"{base_name}.json"
                json_path.write_text(json_content, encoding="utf-8")
                outputs["json"] = json_path

            if "html" in formats:
                html_content = self._generate_html(
                    state, synthesis_result, critique_result, verification_results
                )
                html_path = self.output_dir / f"{base_name}.html"
                html_path.write_text(html_content, encoding="utf-8")
                outputs["html"] = html_path

            return PublishResult(
                run_id=state.run_id,
                timestamp=timestamp,
                output_files=outputs,
            )

    def _generate_markdown(
        self,
        state: CDRState,
        synthesis_result: "SynthesisResult",
        critique_result: "CritiqueResult | None",
        verification_results: dict[str, VerificationResult] | None,
    ) -> str:
        """Generate Markdown report."""
        pico = state.pico
        prisma = state.prisma_counts or PRISMACounts()

        # Build sections
        executive_summary = self._build_executive_summary(synthesis_result, critique_result)

        study_summaries = self._build_study_summaries(state.study_cards)
        rob2_summary = self._build_rob2_summary(state.rob2_results)
        grade_table = self._build_grade_table(synthesis_result.claims)

        verification_summary = ""
        if self.include_verification and verification_results:
            verification_summary = self._build_verification_summary(verification_results)

        references = self._build_references(state.get_included_records())

        # Fill template
        return MARKDOWN_TEMPLATE.format(
            title=f"Systematic Review: {state.question[:50]}...",
            timestamp=datetime.now().isoformat(),
            run_id=state.run_id,
            executive_summary=executive_summary,
            research_question=state.question,
            pico_population=pico.population if pico else "Not specified",
            pico_intervention=pico.intervention if pico else "Not specified",
            pico_comparator=pico.comparator if pico else "Not specified",
            pico_outcome=pico.outcome if pico else "Not specified",
            search_strategy=self._format_search_strategy(state),
            prisma_flowchart=self._build_prisma_text(prisma),
            identified=prisma.records_identified,
            deduplicated=prisma.records_identified - prisma.duplicates_removed,
            screened=prisma.records_screened,
            assessed=prisma.reports_assessed,
            included=prisma.studies_included,
            rob2_summary=rob2_summary,
            study_summaries=study_summaries,
            synthesis_narrative=synthesis_result.overall_narrative,
            grade_table=grade_table,
            key_findings=self._build_key_findings(synthesis_result.claims),
            limitations=self._build_limitations(critique_result),
            implications=self._build_implications(synthesis_result),
            verification_summary=verification_summary,
            references=references,
            appendix_studies=self._build_appendix_studies(state.study_cards)
            if self.include_appendices
            else "",
            appendix_rob2=self._build_appendix_rob2(state.rob2_results)
            if self.include_appendices
            else "",
            appendix_data="See supplementary materials" if self.include_appendices else "",
        )

    def _generate_json(
        self,
        state: CDRState,
        synthesis_result: "SynthesisResult",
        critique_result: "CritiqueResult | None",
        verification_results: dict[str, VerificationResult] | None,
    ) -> str:
        """Generate JSON report.

        MEDIUM-5 sync: Include executed_searches for PRISMA-S compliance.
        """
        report = {
            "meta": {
                "run_id": state.run_id,
                "generated_at": datetime.now().isoformat(),
                "version": "1.1",  # Updated for PRISMA-S support
            },
            "research_question": state.question,
            "pico": state.pico.model_dump() if state.pico else None,
            "prisma_counts": state.prisma_counts.model_dump() if state.prisma_counts else None,
            # PRISMA-S: Executed search details
            "executed_searches": [
                {
                    "database": search.database,
                    "query_planned": search.query_planned,
                    "query_executed": search.query_executed,
                    "executed_at": search.executed_at.isoformat() if search.executed_at else None,
                    "results_count": search.results_count,
                    "results_fetched": search.results_fetched,
                    "notes": search.notes,
                }
                for search in state.executed_searches
            ],
            "included_studies": [
                {
                    "record_id": card.record_id,
                    "study_type": card.study_type.value if card.study_type else None,
                    "sample_size": card.sample_size,
                    "outcomes": [
                        {
                            "name": o.name,
                            "value": o.value,
                            "measure_type": o.measure_type.value if o.measure_type else None,
                            "ci_lower": o.ci_lower,
                            "ci_upper": o.ci_upper,
                            "p_value": o.p_value,
                        }
                        for o in card.outcomes
                    ],
                }
                for card in state.study_cards
            ],
            "rob2_results": [
                {
                    "record_id": result.record_id,
                    "overall_judgment": result.overall_judgment.value
                    if result.overall_judgment
                    else None,
                    "domains": {d.domain.value: d.judgment.value for d in result.domains}
                    if result.domains
                    else {},
                }
                for result in state.rob2_results
            ],
            "claims": [
                {
                    "claim_id": claim.claim_id,
                    "statement": claim.claim_text,
                    "certainty": claim.certainty.value,
                    "supporting_snippets": claim.supporting_snippet_ids,
                }
                for claim in synthesis_result.claims
            ],
            "heterogeneity": synthesis_result.heterogeneity_assessment,
            "narrative": synthesis_result.overall_narrative,
            "disclaimer": (
                "\u26a0\ufe0f This report is machine-generated by CDR (Clinical Deep Research). "
                "It is NOT medical advice and should NOT be used for clinical decision-making. "
                "All findings require independent verification by qualified professionals. "
                "See DISCLAIMER.md for full terms."
            ),
        }

        if critique_result:
            report["critiques"] = {
                "overall_confidence": critique_result.overall_confidence.value,
                "key_concerns": critique_result.key_concerns,
                "strengths": critique_result.strengths,
                "recommendation": critique_result.recommendation,
            }

        if verification_results:
            report["verification"] = {
                claim_id: {
                    "status": result.overall_status.value,
                    "confidence": result.overall_confidence,
                }
                for claim_id, result in verification_results.items()
            }

        return json.dumps(report, indent=2, ensure_ascii=False)

    def _generate_html(
        self,
        state: CDRState,
        synthesis_result: "SynthesisResult",
        critique_result: "CritiqueResult | None",
        verification_results: dict[str, VerificationResult] | None,
    ) -> str:
        """Generate HTML report."""
        # Build HTML content
        content_parts = []

        # Title and meta
        content_parts.append(f"<h1>{state.question}</h1>")
        content_parts.append(f'<p class="meta">Run ID: {state.run_id}</p>')

        # PICO
        if state.pico:
            content_parts.append("<h2>Research Framework (PICO)</h2>")
            content_parts.append("<ul>")
            content_parts.append(f"<li><strong>Population:</strong> {state.pico.population}</li>")
            content_parts.append(
                f"<li><strong>Intervention:</strong> {state.pico.intervention}</li>"
            )
            content_parts.append(
                f"<li><strong>Comparator:</strong> {state.pico.comparator or 'Not specified'}</li>"
            )
            content_parts.append(f"<li><strong>Outcome:</strong> {state.pico.outcome}</li>")
            content_parts.append("</ul>")

        # PRISMA
        if state.prisma_counts:
            p = state.prisma_counts
            content_parts.append("<h2>Study Selection</h2>")
            content_parts.append('<div class="prisma">')
            content_parts.append(
                f'<div class="prisma-box">Identified<br><strong>{p.records_identified}</strong></div>'
            )
            content_parts.append(
                f'<div class="prisma-box">Screened<br><strong>{p.records_screened}</strong></div>'
            )
            content_parts.append(
                f'<div class="prisma-box">Assessed<br><strong>{p.reports_assessed}</strong></div>'
            )
            content_parts.append(
                f'<div class="prisma-box">Included<br><strong>{p.studies_included}</strong></div>'
            )
            content_parts.append("</div>")

        # Claims
        content_parts.append("<h2>Evidence Claims</h2>")
        for claim in synthesis_result.claims:
            certainty_class = f"claim-{claim.certainty.value}"
            cert_badge_class = f"certainty-{claim.certainty.value}"

            content_parts.append(f'<div class="claim {certainty_class}">')
            content_parts.append(
                f'<span class="certainty {cert_badge_class}">{claim.certainty.value.upper()}</span>'
            )
            content_parts.append(f"<p><strong>{claim.claim_text}</strong></p>")
            content_parts.append(f"<p>Supporting snippets: {len(claim.supporting_snippet_ids)}</p>")

            # Note: Only snippet IDs available; full snippets resolved at synthesis time
            if claim.supporting_snippet_ids:
                content_parts.append(
                    f'<div class="snippet">Supported by {len(claim.supporting_snippet_ids)} snippet(s)</div>'
                )

            content_parts.append("</div>")

        # Verification
        if verification_results:
            content_parts.append("<h2>Verification Status</h2>")
            for claim_id, result in verification_results.items():
                status_class = result.overall_status.value.lower()
                content_parts.append(f'<div class="verification {status_class}">')
                content_parts.append(f"<strong>{claim_id}</strong>: {result.overall_status.value}")
                content_parts.append(f" (confidence: {result.overall_confidence:.2f})")
                content_parts.append("</div>")

        content = "\n".join(content_parts)

        return HTML_TEMPLATE.format(
            title=f"CDR Report: {state.question[:50]}...",
            content=content,
            timestamp=datetime.now().isoformat(),
        )

    # =========================================================================
    # HELPER METHODS
    # =========================================================================

    def _build_executive_summary(
        self,
        synthesis_result: "SynthesisResult",
        critique_result: "CritiqueResult | None",
    ) -> str:
        """Build executive summary section."""
        lines = []

        # Claim summary
        high = len(synthesis_result.high_certainty_claims)
        total = synthesis_result.claim_count

        lines.append(f"This review synthesized evidence into **{total} claims**.")
        if high > 0:
            lines.append(f"Of these, **{high}** have high certainty (GRADE).")

        # Top claims
        if synthesis_result.claims:
            lines.append("\n**Key findings:**")
            for claim in synthesis_result.claims[:3]:
                lines.append(f"- {claim.claim_text} [{claim.certainty.value}]")

        # Critique summary
        if critique_result:
            lines.append(f"\n**Overall confidence:** {critique_result.overall_confidence.value}")
            if critique_result.key_concerns:
                lines.append(f"**Main concern:** {critique_result.key_concerns[0]}")

        return "\n".join(lines)

    def _build_study_summaries(self, cards: list[StudyCard]) -> str:
        """Build study summary table."""
        if not cards:
            return "*No studies included*"

        lines = ["| Study | Design | N | Key Outcome |", "|-------|--------|---|-------------|"]

        for card in cards:
            design = card.study_type.value if card.study_type else "NR"
            n = card.sample_size or "NR"
            outcome = card.outcomes[0].name if card.outcomes else "NR"
            lines.append(f"| {card.record_id} | {design} | {n} | {outcome} |")

        return "\n".join(lines)

    def _build_rob2_summary(self, rob2_results: list[RoB2Result]) -> str:
        """Build RoB2 summary.

        MEDIUM-5 fix: Updated to accept list instead of dict.
        Refs: CDR_Integral_Audit_2026-01-20.md MEDIUM-5
        """
        if not rob2_results:
            return "*No risk of bias assessment performed*"

        lines = ["| Study | Overall Risk |", "|-------|--------------|"]

        for result in rob2_results:
            judgment = result.overall_judgment.value if result.overall_judgment else "not_assessed"
            lines.append(f"| {result.record_id} | {judgment} |")

        return "\n".join(lines)

    def _build_grade_table(self, claims: list[EvidenceClaim]) -> str:
        """Build GRADE summary of findings table."""
        if not claims:
            return "*No claims synthesized*"

        lines = [
            "| Outcome | Certainty | Studies | Summary |",
            "|---------|-----------|---------|---------|",
        ]

        for claim in claims:
            snippets = len(claim.supporting_snippet_ids)
            summary = (
                claim.claim_text[:50] + "..." if len(claim.claim_text) > 50 else claim.claim_text
            )
            lines.append(f"| {claim.claim_id} | {claim.certainty.value} | {snippets} | {summary} |")

        return "\n".join(lines)

    def _build_verification_summary(
        self,
        results: dict[str, VerificationResult],
    ) -> str:
        """Build verification summary."""
        verified = sum(
            1 for r in results.values() if r.overall_status == VerificationStatus.VERIFIED
        )
        partial = sum(1 for r in results.values() if r.overall_status == VerificationStatus.PARTIAL)
        contradicted = sum(
            1 for r in results.values() if r.overall_status == VerificationStatus.CONTRADICTED
        )
        unverifiable = sum(
            1 for r in results.values() if r.overall_status == VerificationStatus.UNVERIFIABLE
        )

        lines = [
            f"- ✅ Verified: {verified}",
            f"- ⚠️ Partial: {partial}",
            f"- ❌ Contradicted: {contradicted}",
            f"- ❓ Unverifiable: {unverifiable}",
        ]

        return "\n".join(lines)

    def _build_references(self, records: list) -> str:
        """Build references section."""
        if not records:
            return "*No references*"

        lines = []
        for i, record in enumerate(records, 1):
            ref = f"{i}. {record.title}"
            if record.authors:
                ref += f" {record.authors[0]} et al."
            if record.journal:
                ref += f" {record.journal}."
            if record.pmid:
                ref += f" PMID: {record.pmid}"
            lines.append(ref)

        return "\n".join(lines)

    def _format_search_strategy(self, state: CDRState) -> str:
        """Format search strategy description.

        MEDIUM-5 sync: Include executed searches for PRISMA-S compliance.
        Refs: PRISMA-S (BMJ 2021), CDR_Integral_Audit_2026-01-20.md
        """
        lines = ["Databases searched:"]

        if state.search_plan:
            for db in ["PubMed", "ClinicalTrials.gov"]:
                lines.append(f"- {db}")

            if state.search_plan.pubmed_query:
                lines.append(
                    f"\n**PubMed query (planned):** `{state.search_plan.pubmed_query[:200]}...`"
                )

        # PRISMA-S: Include executed search details
        if state.executed_searches:
            lines.append("\n**Executed searches:**")
            for search in state.executed_searches:
                lines.append(
                    f"\n*{search.database}* (executed {search.executed_at.strftime('%Y-%m-%d %H:%M UTC') if search.executed_at else 'N/A'}):"
                )
                lines.append(
                    f"- Query: `{search.query_executed[:150]}...`"
                    if len(search.query_executed) > 150
                    else f"- Query: `{search.query_executed}`"
                )
                lines.append(f"- Results found: {search.results_count}")
                lines.append(f"- Results fetched: {search.results_fetched}")
                if search.notes:
                    lines.append(f"- Notes: {search.notes}")

        return "\n".join(lines)

    def _build_prisma_text(self, prisma: PRISMACounts) -> str:
        """Build text PRISMA flow.

        MEDIUM-5 fix: Updated to use correct field names and include exclusion reasons.
        Refs: CDR_Integral_Audit_2026-01-20.md MEDIUM-5, PRISMA 2020
        """
        flow_text = f"""
```
Identification → Screening → Eligibility → Included
     {prisma.records_identified}    →    {prisma.records_screened}    →    {prisma.reports_assessed}    →    {prisma.studies_included}
```
"""
        # Add exclusion breakdown if available (PRISMA 2020 requirement)
        if prisma.exclusion_reasons:
            flow_text += "\n**Exclusion reasons at screening:**\n"
            for reason, count in sorted(
                prisma.exclusion_reasons.items(), key=lambda x: x[1], reverse=True
            ):
                flow_text += f"- {reason}: {count}\n"

        return flow_text

    def _build_key_findings(self, claims: list[EvidenceClaim]) -> str:
        """Build key findings section."""
        lines = []
        for claim in claims[:5]:
            lines.append(f"- **{claim.certainty.value.upper()}**: {claim.claim_text}")
        return "\n".join(lines) or "*No key findings*"

    def _build_limitations(self, critique_result: "CritiqueResult | None") -> str:
        """Build limitations section."""
        if not critique_result:
            return "- Limitations not formally assessed"

        lines = []
        for concern in critique_result.key_concerns[:5]:
            lines.append(f"- {concern}")

        return "\n".join(lines) or "- No major limitations identified"

    def _build_implications(self, synthesis_result: "SynthesisResult") -> str:
        """Build implications section."""
        lines = []

        high_cert = synthesis_result.high_certainty_claims
        if high_cert:
            lines.append("**For clinical practice:**")
            lines.append(f"- {high_cert[0].claim_text}")

        low_cert = synthesis_result.low_certainty_claims
        if low_cert:
            lines.append("\n**For future research:**")
            lines.append(f"- More evidence needed on: {low_cert[0].claim_text[:100]}...")

        return "\n".join(lines) or "*Implications pending further analysis*"

    def _build_appendix_studies(self, cards: list[StudyCard]) -> str:
        """Build detailed study appendix."""
        if not cards:
            return "*No studies*"

        lines = []
        for card in cards:
            lines.append(f"### {card.record_id}")
            lines.append(f"- **Design:** {card.study_type.value if card.study_type else 'NR'}")
            lines.append(f"- **Sample size:** {card.sample_size or 'NR'}")
            if card.intervention_extracted:
                lines.append(f"- **Intervention:** {card.intervention_extracted}")
            lines.append("")

        return "\n".join(lines)

    def _build_appendix_rob2(self, rob2_results: list[RoB2Result]) -> str:
        """Build detailed RoB2 appendix.

        MEDIUM-5 fix: Updated to accept list instead of dict.
        Refs: CDR_Integral_Audit_2026-01-20.md MEDIUM-5
        """
        if not rob2_results:
            return "*No RoB2 assessments*"

        lines = []
        for result in rob2_results:
            lines.append(f"### {result.record_id}")
            judgment = result.overall_judgment.value if result.overall_judgment else "not_assessed"
            lines.append(f"**Overall:** {judgment}")
            if result.domains:
                for domain in result.domains:
                    lines.append(f"- {domain.domain.value}: {domain.judgment.value}")
            lines.append("")

        return "\n".join(lines)


# =============================================================================
# RESULT DATACLASS
# =============================================================================


@dataclass
class PublishResult:
    """Result of publishing operation."""

    run_id: str
    timestamp: str
    output_files: dict[str, Path] = field(default_factory=dict)

    @property
    def markdown_path(self) -> Path | None:
        """Path to Markdown file."""
        return self.output_files.get("markdown")

    @property
    def json_path(self) -> Path | None:
        """Path to JSON file."""
        return self.output_files.get("json")

    @property
    def html_path(self) -> Path | None:
        """Path to HTML file."""
        return self.output_files.get("html")
